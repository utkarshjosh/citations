# ğŸ§  Brain Scroll

> **TikTok for Research Papers** - Swipe through cutting-edge CS research in plain English

Brain Scroll transforms dense academic papers into addictive, swipeable content. Get daily curated papers from arXiv with AI-powered summaries, presented in a full-screen, mobile-first experience designed for maximum engagement.

## âœ¨ What's New (v2.0)

ğŸ”¥ **Complete UI Overhaul** - TikTok/Instagram-style single-card experience
ğŸ¨ **Vibrant Design** - Stunning gradients and modern color palette
ğŸ“± **PWA Ready** - Install to home screen, works offline
â¤ï¸ **Like System** - Full engagement tracking with backend integration
ğŸš€ **Enhanced API** - Retry logic, error handling, trending algorithm
âš¡ **Performance** - Optimized for mobile, smooth 60fps animations

## ğŸŒŸ Features

### Core Experience

- **ğŸ¯ Single-Card Focus**: ONE paper at a time - maximum attention, zero distractions
- **ğŸ‘† Swipe Navigation**: Vertical swipe (up/down) like TikTok - addictive by design
- **ğŸ¨ Vibrant Gradients**: Each category has unique, eye-catching colors
- **ğŸ“± Mobile-First**: Built for phones, optimized for thumbs
- **ğŸ’« Smooth Animations**: Buttery 60fps transitions with Framer Motion

### Content & Discovery

- **ğŸ“š Daily Papers**: Fresh CS research from arXiv (AI, ML, NLP, CV, etc.)
- **ğŸ¤– AI Summaries**: Plain English 3-5 line summaries
- **ğŸ’¡ Why It Matters**: Key insights and practical applications
- **ğŸ”¥ Trending**: Algorithm-powered trending papers
- **ğŸ·ï¸ Categories**: Filter by CS categories with beautiful gradients

### Engagement

- **â¤ï¸ Like System**: Session-based tracking, optimistic UI updates
- **ğŸ”– Save Papers**: Bookmark for later reading
- **ğŸ“¤ Share**: Native share API integration
- **ğŸ“Š View Tracking**: Anonymous engagement metrics

### Technical

- **ğŸ“² PWA**: Install to home screen, works offline
- **ğŸ”„ Auto-Retry**: Network resilience with exponential backoff
- **âš¡ Caching**: Smart caching strategies for performance
- **ğŸ¯ Error Handling**: User-friendly error messages

## ğŸ—ï¸ Architecture

Brain Scroll is built as a modern monorepo with three main components:

```
brain-scroll/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scraper/          # Python agentic paper fetcher with MCP integration
â”‚   â””â”€â”€ paper-search-mcp/ # MCP server for multi-source paper searching
â”œâ”€â”€ api/                  # Node.js/Express REST API
â”œâ”€â”€ frontend/             # React + Vite + Mantine UI
â””â”€â”€ docker-compose.yml    # Full stack orchestration
```

### Technology Stack

**Backend (Scraper)**

- Python 3.11+
- MCP (Model Context Protocol) with paper-search-mcp
- Gemini/Groq LLMs for intelligent summarization
- MongoDB for data storage
- Agentic architecture for autonomous operation

**API**

- Node.js 18+
- Express.js
- MongoDB driver
- Rate limiting & security middleware

**Frontend**

- React 18
- Vite
- Mantine UI
- React Router

**Infrastructure**

- Docker & Docker Compose
- MongoDB 7.0

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Node.js 18+ (for local development)
- Python 3.11+ (for local development)
- MongoDB (or use Docker)

### Environment Setup

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd brain-scroll
   ```

2. **Set up environment variables**

   ```bash
   # Root level
   cp .env.example .env

   # Backend scraper
   cp backend/scraper/.env.example backend/scraper/.env

   # API
   cp api/.env.example api/.env

   # Frontend
   cp frontend/.env.example frontend/.env
   ```

3. **Configure API keys**

   Edit `backend/scraper/.env` and add your LLM API keys:

   ```bash
   GEMINI_API_KEY=your_gemini_api_key
   GROQ_API_KEY=your_groq_api_key  # Optional fallback
   ```

### Running with Docker (Recommended)

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

Services will be available at:

- **Frontend**: http://localhost:5173
- **API**: http://localhost:3000
- **MongoDB**: localhost:27017

### Running Locally (Development)

**Backend Scraper**

```bash
cd backend/scraper
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
python scraper.py
```

**API**

```bash
cd api
npm install
npm run dev
```

**Frontend**

```bash
cd frontend
npm install
npm run dev
```

## ğŸ“¦ Project Structure

```
brain-scroll/
â”œâ”€â”€ .cursor/                    # Cursor IDE configuration
â”‚   â”œâ”€â”€ mcp.json               # MCP server configuration
â”‚   â””â”€â”€ rules/                 # AI coding rules
â”œâ”€â”€ .taskmaster/               # TaskMaster AI project management
â”‚   â”œâ”€â”€ docs/                  # Project documentation
â”‚   â””â”€â”€ tasks/                 # Task definitions
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ agentic_paper_fetcher.py  # Agentic paper fetching with LLM
â”‚   â”‚   â”œâ”€â”€ scraper.py                # Main orchestration
â”‚   â”‚   â”œâ”€â”€ db_connection.py          # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ deduplication.py          # Duplicate detection
â”‚   â”‚   â”œâ”€â”€ config.py                 # Configuration
â”‚   â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ paper-search-mcp/      # MCP server for paper searching
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/            # API routes
â”‚   â”‚   â”œâ”€â”€ controllers/       # Business logic
â”‚   â”‚   â”œâ”€â”€ middleware/        # Express middleware
â”‚   â”‚   â”œâ”€â”€ models/            # Data models
â”‚   â”‚   â””â”€â”€ index.js           # Entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â”œâ”€â”€ hooks/             # Custom hooks
â”‚   â”‚   â”œâ”€â”€ utils/             # Utilities
â”‚   â”‚   â””â”€â”€ styles/            # CSS styles
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml         # Multi-container orchestration
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .eslintrc.json            # JavaScript linting
â”œâ”€â”€ .prettierrc               # Code formatting
â”œâ”€â”€ .editorconfig             # Editor configuration
â””â”€â”€ README.md
```

## ğŸ¤– Agentic Architecture

Brain Scroll uses an **agentic approach** for paper scraping:

1. **MCP Integration**: Uses [paper-search-mcp](https://github.com/openags/paper-search-mcp) for multi-source paper discovery
2. **LLM-Powered**: Gemini/Groq models generate intelligent summaries and insights
3. **Autonomous**: Can be scheduled to run independently
4. **Multi-Source**: Supports arXiv, PubMed, bioRxiv, and more

## ğŸ§ª Testing

**Backend**

```bash
cd backend/scraper
python test_scraper.py
```

**API**

```bash
cd api
npm test
```

**Frontend**

```bash
cd frontend
npm test
```

## ğŸ“ Development Workflow

1. **Code Standards**: Follow ESLint, Prettier, and Flake8 configurations
2. **Git Workflow**: Feature branches â†’ Pull requests â†’ Main
3. **Testing**: Write tests for new features
4. **Documentation**: Update README and inline docs

## ğŸ”§ Configuration

### CS Categories

Edit `backend/scraper/config.py` to customize categories:

```python
CS_CATEGORIES = [
    "cs.AI",   # Artificial Intelligence
    "cs.CL",   # Computation and Language (NLP)
    "cs.LG",   # Machine Learning
    "cs.CV",   # Computer Vision
    "cs.NE",   # Neural and Evolutionary Computing
    "cs.RO",   # Robotics
    "cs.IR",   # Information Retrieval
]
```

### Scraping Schedule

Configure cron job for daily scraping:

```bash
# Run daily at 6 AM
0 6 * * * cd /path/to/brain-scroll/backend/scraper && python scraper.py
```

## ğŸš¢ Deployment

### Docker Production

```bash
# Build and start in production mode
docker-compose -f docker-compose.yml up -d --build

# Scale services
docker-compose up -d --scale api=3
```

### Environment Variables

See `.env.example` files in each directory for required configuration.

## ğŸ“Š Monitoring

- **API Health**: http://localhost:3000/health
- **MongoDB**: Use MongoDB Compass or mongosh
- **Logs**: `docker-compose logs -f [service-name]`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- [arXiv](https://arxiv.org/) for providing open access to research papers
- [paper-search-mcp](https://github.com/openags/paper-search-mcp) for MCP integration
- [Mantine](https://mantine.dev/) for the beautiful UI components

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**Built with â¤ï¸ for the research community**
