1. Data Layer

MongoDB â†’ store paper metadata + processed summaries.

{
  "title": "...",
  "authors": ["..."],
  "arxiv_url": "...",
  "summary": "...",
  "why_it_matters": "...",
  "applications": "...",
  "createdAt": "2025-10-01"
}

2. Scraper + Processor (Python)

Use arXiv API (arxiv Python lib).

Process new papers daily (e.g., cron job).

Send abstract â†’ LangGraph flow with LLM summarizer nodes:

Step 1: Summarize in plain English (3 lines).

Step 2: Generate "Why it matters".

Step 3: Suggest "Applications".

Insert into MongoDB.

3. API Layer (Node + Express)

Provides REST endpoints for frontend:

GET /feed â†’ latest papers (paginated).

POST /like/:paperId â†’ record user interest (for personalization later).

GET /trending â†’ most liked/shared papers.

4. Frontend (React + UI Framework)

Choose UI framework thatâ€™s popular & easy for feed apps:

Chakra UI â†’ simple, modern, lightweight.

Mantine â†’ great components, infinite scroll support.

Shadcn/UI + Tailwind â†’ developer favorite, but setup heavier.
ğŸ‘‰ For speed: Mantine (infinite scroll, cards, notifications out-of-the-box).

UI components:

Feed page: card view, scrollable feed.

Paper card:

Title (clickable â†’ arXiv link)

3â€“4 line summary

Why it matters & applications (collapsible)

â¤ï¸ Like button

5. Optional Notifications

For prototype: just have a "Subscribe" field (email).

Later: connect Node â†’ Resend/Postmark for daily digest.

ğŸ”¹ Prototype Flow (User Journey)

Landing page â†’ "Daily AI Research Digest"

CTA: "See todayâ€™s highlights"

Feed scroll starts.

Feed â†’ shows cards (title + summary + quick actions).

Interaction â†’ like/share.

Backend â†’ likes stored, used later for "Trending".

(Optional MVP+) Daily email digest for signed-up users.